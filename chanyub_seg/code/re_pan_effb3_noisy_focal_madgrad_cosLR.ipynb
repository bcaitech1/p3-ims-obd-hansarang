{"nbformat":4,"nbformat_minor":0,"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"297.278px"},"toc_section_display":true,"toc_window_display":true},"colab":{"name":"re_pan_effb3_noisy_focal_madgrad_cosLR.ipynb","provenance":[],"toc_visible":true},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4402a1e740bd4888b86cc4556b27c378":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b68a6f5a4f2b4a0587c6fc8af607dce9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f91fc9dc65df4130ae7ecd4d33b9cccc","IPY_MODEL_1973c413c6ec4b76a50379c8b7d371c5"]}},"b68a6f5a4f2b4a0587c6fc8af607dce9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f91fc9dc65df4130ae7ecd4d33b9cccc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c63980e4d8a3408f934f352a1588097b","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":49385734,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":49385734,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_95df5be81ac945d29bf955076121ffc6"}},"1973c413c6ec4b76a50379c8b7d371c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cc93f19734c34e318cba7fd84da9ab53","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 47.1M/47.1M [00:02&lt;00:00, 18.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7d2ca5494fed48a08528d0a4544a70cd"}},"c63980e4d8a3408f934f352a1588097b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"95df5be81ac945d29bf955076121ffc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cc93f19734c34e318cba7fd84da9ab53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7d2ca5494fed48a08528d0a4544a70cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GW8gF48g-WSK","executionInfo":{"status":"ok","timestamp":1620204675839,"user_tz":-540,"elapsed":86311,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"c3f7ad1c-738c-488d-ee67-e5aa97b6858b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xDwpp4Lk-gSH","executionInfo":{"status":"ok","timestamp":1620204675841,"user_tz":-540,"elapsed":7672,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"9e7c6f65-e721-4c3d-debc-388ccd77e0cb"},"source":["ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sItrVDeh-iYC","executionInfo":{"status":"ok","timestamp":1620204678380,"user_tz":-540,"elapsed":9562,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"0e80c310-6e56-41d4-d798-f263e25d316c"},"source":["cd drive/MyDrive/Trash/code"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Trash/code\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a54v4-kN_LVO","executionInfo":{"status":"ok","timestamp":1620204686893,"user_tz":-540,"elapsed":17590,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"59a75ec3-0a92-42f5-ff2b-53fc794fc72f"},"source":["!pip install albumentations==0.5.2"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting albumentations==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/58/63fb1d742dc42d9ba2800ea741de1f2bc6bb05548d8724aa84794042eaf2/albumentations-0.5.2-py3-none-any.whl (72kB)\n","\r\u001b[K     |████▌                           | 10kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20kB 10.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 30kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 40kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 71kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.8MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.5.2) (3.13)\n","Collecting opencv-python-headless>=4.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/6d/92f377bece9b0ec9c893081dbe073a65b38d7ac12ef572b8f70554d08760/opencv_python_headless-4.5.1.48-cp37-cp37m-manylinux2014_x86_64.whl (37.6MB)\n","\u001b[K     |████████████████████████████████| 37.6MB 75.6MB/s \n","\u001b[?25hRequirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.5.2) (0.16.2)\n","Collecting imgaug>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n","\u001b[K     |████████████████████████████████| 952kB 53.0MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.5.2) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.5.2) (1.19.5)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (2.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (2.5.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (1.1.1)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (7.1.2)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (3.2.2)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (1.7.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (1.15.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (4.1.2.30)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations==0.5.2) (4.4.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (1.3.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (2.4.7)\n","Installing collected packages: opencv-python-headless, imgaug, albumentations\n","  Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","  Found existing installation: albumentations 0.1.12\n","    Uninstalling albumentations-0.1.12:\n","      Successfully uninstalled albumentations-0.1.12\n","Successfully installed albumentations-0.5.2 imgaug-0.4.0 opencv-python-headless-4.5.1.48\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-18T10:34:47.826930Z","start_time":"2021-04-18T10:34:45.406686Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"l_LPA4XD-NwC","executionInfo":{"status":"ok","timestamp":1620204727687,"user_tz":-540,"elapsed":6974,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"0e1e32a5-0820-4746-fbf7-f0fa25f2a7f2"},"source":["import os\n","import random\n","import time\n","import json\n","import warnings \n","warnings.filterwarnings('ignore')\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from utils import label_accuracy_score\n","import cv2\n","\n","import numpy as np\n","import pandas as pd\n","\n","# 전처리를 위한 라이브러리\n","from pycocotools.coco import COCO\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","# 시각화를 위한 라이브러리\n","import matplotlib.pyplot as plt\n","import seaborn as sns; sns.set()\n","\n","plt.rcParams['axes.grid'] = False\n","\n","print('pytorch version: {}'.format(torch.__version__))\n","print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n","\n","print(torch.cuda.get_device_name(0))\n","print(torch.cuda.device_count())\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"],"execution_count":5,"outputs":[{"output_type":"stream","text":["pytorch version: 1.8.1+cu101\n","GPU 사용 가능 여부: True\n","Tesla P100-PCIE-16GB\n","1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HxgRSL_M-NwF"},"source":["## 하이퍼파라미터 세팅 및 seed 고정"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-18T10:34:47.841930Z","start_time":"2021-04-18T10:34:47.827931Z"},"id":"rV3JmGP5-NwF","executionInfo":{"status":"ok","timestamp":1620204727690,"user_tz":-540,"elapsed":2843,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}}},"source":["batch_size = 8   # Mini-batch size\n","num_epochs = 20\n","learning_rate = 0.0001"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-18T10:34:47.856930Z","start_time":"2021-04-18T10:34:47.842931Z"},"id":"Z6LOuJXQ-NwG","executionInfo":{"status":"ok","timestamp":1620204727694,"user_tz":-540,"elapsed":2622,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}}},"source":["# seed 고정\n","random_seed = 42\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","# torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(random_seed)\n","random.seed(random_seed)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iWF_EJDu-NwG"},"source":["## 학습 데이터 EDA"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-18T10:34:51.381961Z","start_time":"2021-04-18T10:34:47.857930Z"},"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"lg0x0D0a-NwG","executionInfo":{"status":"ok","timestamp":1620204768150,"user_tz":-540,"elapsed":9406,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"ffe09570-4048-4bd0-aa90-daa68707ec44"},"source":["%matplotlib inline\n","\n","dataset_path = '../input/data'\n","anns_file_path = dataset_path + '/' + 'train.json'\n","\n","# Read annotations\n","with open(anns_file_path, 'r') as f:\n","    dataset = json.loads(f.read())\n","\n","categories = dataset['categories']\n","anns = dataset['annotations']\n","imgs = dataset['images']\n","nr_cats = len(categories)\n","nr_annotations = len(anns)\n","nr_images = len(imgs)\n","\n","# Load categories and super categories\n","cat_names = []\n","super_cat_names = []\n","super_cat_ids = {}\n","super_cat_last_name = ''\n","nr_super_cats = 0\n","for cat_it in categories:\n","    cat_names.append(cat_it['name'])\n","    super_cat_name = cat_it['supercategory']\n","    # Adding new supercat\n","    if super_cat_name != super_cat_last_name:\n","        super_cat_names.append(super_cat_name)\n","        super_cat_ids[super_cat_name] = nr_super_cats\n","        super_cat_last_name = super_cat_name\n","        nr_super_cats += 1\n","\n","print('Number of super categories:', nr_super_cats)\n","print('Number of categories:', nr_cats)\n","print('Number of annotations:', nr_annotations)\n","print('Number of images:', nr_images)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Number of super categories: 11\n","Number of categories: 11\n","Number of annotations: 21116\n","Number of images: 2617\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-18T10:34:51.546964Z","start_time":"2021-04-18T10:34:51.382969Z"},"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":355},"id":"PjLyVHVY-NwH","executionInfo":{"status":"ok","timestamp":1620204768158,"user_tz":-540,"elapsed":7009,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"9330af92-45b3-4133-811c-2d95ef43a9da"},"source":["# Count annotations\n","cat_histogram = np.zeros(nr_cats,dtype=int)\n","for ann in anns:\n","    cat_histogram[ann['category_id']] += 1\n","\n","# Initialize the matplotlib figure\n","f, ax = plt.subplots(figsize=(5,5))\n","\n","# Convert to DataFrame\n","df = pd.DataFrame({'Categories': cat_names, 'Number of annotations': cat_histogram})\n","df = df.sort_values('Number of annotations', 0, False)\n","\n","# Plot the histogram\n","plt.title(\"category distribution of train set \")\n","plot_1 = sns.barplot(x=\"Number of annotations\", y=\"Categories\", data=df, label=\"Total\", color=\"b\")"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 360x360 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-18T10:34:51.561965Z","start_time":"2021-04-18T10:34:51.547969Z"},"id":"34Tw5__i-NwI","executionInfo":{"status":"ok","timestamp":1620204768159,"user_tz":-540,"elapsed":4034,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}}},"source":["# category labeling \n","sorted_temp_df = df.sort_index()\n","\n","# background = 0 에 해당되는 label 추가 후 기존들을 모두 label + 1 로 설정\n","sorted_df = pd.DataFrame([\"Backgroud\"], columns = [\"Categories\"])\n","sorted_df = sorted_df.append(sorted_temp_df, ignore_index=True)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-18T10:34:51.576961Z","start_time":"2021-04-18T10:34:51.562964Z"},"colab":{"base_uri":"https://localhost:8080/","height":421},"id":"CQk4vV5N-NwI","executionInfo":{"status":"ok","timestamp":1620204773023,"user_tz":-540,"elapsed":8478,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"842dbc56-55ec-4e3f-c911-a6a5c4e2b21e"},"source":["# class (Categories) 에 따른 index 확인 (0~11 : 총 12개)\n","sorted_df"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Categories</th>\n","      <th>Number of annotations</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Backgroud</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>UNKNOWN</td>\n","      <td>128.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>General trash</td>\n","      <td>2225.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Paper</td>\n","      <td>7448.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Paper pack</td>\n","      <td>527.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Metal</td>\n","      <td>449.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Glass</td>\n","      <td>488.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Plastic</td>\n","      <td>2472.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Styrofoam</td>\n","      <td>1074.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Plastic bag</td>\n","      <td>6114.0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Battery</td>\n","      <td>50.0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Clothing</td>\n","      <td>141.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Categories  Number of annotations\n","0       Backgroud                    NaN\n","1         UNKNOWN                  128.0\n","2   General trash                 2225.0\n","3           Paper                 7448.0\n","4      Paper pack                  527.0\n","5           Metal                  449.0\n","6           Glass                  488.0\n","7         Plastic                 2472.0\n","8       Styrofoam                 1074.0\n","9     Plastic bag                 6114.0\n","10        Battery                   50.0\n","11       Clothing                  141.0"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"KXU0zmZs-NwI"},"source":["## 데이터 전처리 함수 정의 (Dataset)"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-18T10:34:52.693328Z","start_time":"2021-04-18T10:34:52.681328Z"},"id":"QFnTI8_Z-NwJ","executionInfo":{"status":"ok","timestamp":1620204777487,"user_tz":-540,"elapsed":2707,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}}},"source":["category_names = list(sorted_df.Categories)\n","\n","def get_classname(classID, cats):\n","    for i in range(len(cats)):\n","        if cats[i]['id']==classID:\n","            return cats[i]['name']\n","    return \"None\"\n","\n","class CustomDataLoader(Dataset):\n","    \"\"\"COCO format\"\"\"\n","    def __init__(self, data_dir, mode = 'train', transform = None):\n","        super().__init__()\n","        self.mode = mode\n","        self.transform = transform\n","        self.coco = COCO(data_dir)\n","        \n","    def __getitem__(self, index: int):\n","        # dataset이 index되어 list처럼 동작\n","        image_id = self.coco.getImgIds(imgIds=index)\n","        image_infos = self.coco.loadImgs(image_id)[0]\n","        \n","        # cv2 를 활용하여 image 불러오기\n","        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n","        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n","        images /= 255.0\n","        \n","        if (self.mode in ('train', 'val')):\n","            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n","            anns = self.coco.loadAnns(ann_ids)\n","\n","            # Load the categories in a variable\n","            cat_ids = self.coco.getCatIds()\n","            cats = self.coco.loadCats(cat_ids)\n","\n","            # masks : size가 (height x width)인 2D\n","            # 각각의 pixel 값에는 \"category id + 1\" 할당\n","            # Background = 0\n","            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n","            # Unknown = 1, General trash = 2, ... , Cigarette = 11\n","            for i in range(len(anns)):\n","                className = get_classname(anns[i]['category_id'], cats)\n","                pixel_value = category_names.index(className)\n","                masks = np.maximum(self.coco.annToMask(anns[i])*pixel_value, masks)\n","            masks = masks.astype(np.float32)\n","\n","            # transform -> albumentations 라이브러리 활용\n","            if self.transform is not None:\n","                transformed = self.transform(image=images, mask=masks)\n","                images = transformed[\"image\"]\n","                masks = transformed[\"mask\"]\n","            \n","            return images, masks, image_infos\n","        \n","        if self.mode == 'test':\n","            # transform -> albumentations 라이브러리 활용\n","            if self.transform is not None:\n","                transformed = self.transform(image=images)\n","                images = transformed[\"image\"]\n","            \n","            return images, image_infos\n","    \n","    \n","    def __len__(self) -> int:\n","        # 전체 dataset의 size를 return\n","        return len(self.coco.getImgIds())"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cp2aIOlP-NwK"},"source":["## Dataset 정의 및 DataLoader 할당"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-18T10:34:58.823175Z","start_time":"2021-04-18T10:34:54.106233Z"},"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"P7zFlRn6-NwK","executionInfo":{"status":"ok","timestamp":1620204791959,"user_tz":-540,"elapsed":11468,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"19d2d9e7-5bb7-47d7-e9be-fbe178824532"},"source":["# train.json / validation.json / test.json 디렉토리 설정\n","train_path = dataset_path + '/train.json'\n","val_path = dataset_path + '/val.json'\n","test_path = dataset_path + '/test.json'\n","\n","# collate_fn needs for batch\n","def collate_fn(batch):\n","    return tuple(zip(*batch))\n","\n","train_transform = A.Compose([\n","                            ToTensorV2()\n","                            ])\n","\n","val_transform = A.Compose([\n","                          ToTensorV2()\n","                          ])\n","\n","test_transform = A.Compose([\n","                           ToTensorV2()\n","                           ])\n","\n","# create own Dataset 1 (skip)\n","# validation set을 직접 나누고 싶은 경우\n","# random_split 사용하여 data set을 8:2 로 분할\n","# train_size = int(0.8*len(dataset))\n","# val_size = int(len(dataset)-train_size)\n","# dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=transform)\n","# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n","\n","# create own Dataset 2\n","# train dataset\n","train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n","\n","# validation dataset\n","val_dataset = CustomDataLoader(data_dir=val_path, mode='val', transform=val_transform)\n","\n","# test dataset\n","test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n","\n","\n","# DataLoader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           num_workers=4,\n","                                           collate_fn=collate_fn,\n","                                           drop_last=True)\n","\n","val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n","                                         batch_size=batch_size,\n","                                         shuffle=False,\n","                                         num_workers=4,\n","                                         collate_fn=collate_fn,\n","                                         drop_last=True)                                         \n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          num_workers=4,\n","                                          collate_fn=collate_fn)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["loading annotations into memory...\n","Done (t=3.85s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=3.25s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=0.51s)\n","creating index...\n","index created!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8rqJiHb_-NwM"},"source":["# wandb"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1kHXm0uAX3R","executionInfo":{"status":"ok","timestamp":1620085447186,"user_tz":-540,"elapsed":16341,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"1ca945cd-0b7d-4981-e118-6147e81d4af1"},"source":["!pip install wandb"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/ee/d755f9e5466df64c8416a2c6a860fb3aaa43ed6ea8e8e8e81460fda5788b/wandb-0.10.28-py2.py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 4.3MB/s \n","\u001b[?25hCollecting configparser>=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n","Collecting docker-pycreds>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting sentry-sdk>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 36.3MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n","Collecting GitPython>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 34.3MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n","Collecting pathtools\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Collecting shortuuid>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting subprocess32>=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 13.4MB/s \n","\u001b[?25hRequirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.5MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.0.0)\n","Collecting smmap<5,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n","Building wheels for collected packages: pathtools, subprocess32\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=2de7dd8da7759d160deb90aec41a174a0805b6480a7c2ec10348f94031c5eb33\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=b1ffeee148a0368285ddc00ea711cdd2d892b8b36008b5a313ad9fda754a6099\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","Successfully built pathtools subprocess32\n","Installing collected packages: configparser, docker-pycreds, sentry-sdk, smmap, gitdb, GitPython, pathtools, shortuuid, subprocess32, wandb\n","Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.28\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"aMW4VV9V-NwM","executionInfo":{"status":"error","timestamp":1620204796451,"user_tz":-540,"elapsed":1584,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"64db9564-74fb-491c-84ea-9b0818566525"},"source":["import wandb\n","\n","proj_name = 're_pan_effb3_noisy_focal_madgrad_cosLR'\n","\n","wandb.init(project='chanyub',name=proj_name)\n","\n","config = wandb.config\n","config.learning_rate = 0.01"],"execution_count":14,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-ab05931f6ab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mproj_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m're_pan_effb3_noisy_focal_madgrad_cosLR'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'chanyub'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproj_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'wandb' has no attribute 'init'"]}]},{"cell_type":"markdown","metadata":{"id":"uQRiIVGX-NwM"},"source":["## My model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S0xCGpNeAqeD","executionInfo":{"status":"ok","timestamp":1620204809194,"user_tz":-540,"elapsed":6778,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"ce6050e9-7d0b-4ab8-8744-71243bce5c49"},"source":["!pip install segmentation_models_pytorch"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Collecting segmentation_models_pytorch\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/54/8953f9f7ee9d451b0f3be8d635aa3a654579abf898d17502a090efe1155a/segmentation_models_pytorch-0.1.3-py3-none-any.whl (66kB)\n","\r\u001b[K     |█████                           | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (0.9.1+cu101)\n","Collecting efficientnet-pytorch==0.6.3\n","  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n","Collecting timm==0.3.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/2d/39ecc56fbb202e1891c317e8e44667299bc3b0762ea2ed6aaaa2c2f6613c/timm-0.3.2-py3-none-any.whl (244kB)\n","\u001b[K     |████████████████████████████████| 245kB 8.2MB/s \n","\u001b[?25hCollecting pretrainedmodels==0.7.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n","\u001b[?25hRequirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (1.8.1+cu101)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (1.19.5)\n","Collecting munch\n","  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.41.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision>=0.3.0->segmentation_models_pytorch) (3.7.4.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\n","Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp37-none-any.whl size=12420 sha256=4ca515854968cacdfb9b4854cb80de229ce128c68183a69c1031515364c1e168\n","  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp37-none-any.whl size=60963 sha256=f55b554c00dc838956b2f60b74cd6919fcf71e457015a8f0750b8effdce1c857\n","  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n","Successfully built efficientnet-pytorch pretrainedmodels\n","Installing collected packages: efficientnet-pytorch, timm, munch, pretrainedmodels, segmentation-models-pytorch\n","Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.1.3 timm-0.3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-18T16:16:11.634792Z","start_time":"2021-04-18T16:16:05.875817Z"},"colab":{"base_uri":"https://localhost:8080/","height":137,"referenced_widgets":["4402a1e740bd4888b86cc4556b27c378","b68a6f5a4f2b4a0587c6fc8af607dce9","f91fc9dc65df4130ae7ecd4d33b9cccc","1973c413c6ec4b76a50379c8b7d371c5","c63980e4d8a3408f934f352a1588097b","95df5be81ac945d29bf955076121ffc6","cc93f19734c34e318cba7fd84da9ab53","7d2ca5494fed48a08528d0a4544a70cd"]},"id":"a8IfZfiM-NwM","executionInfo":{"status":"ok","timestamp":1620204825293,"user_tz":-540,"elapsed":18561,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"4b480ea7-4cfa-4205-a360-8c8a5d4b702c"},"source":["# 구현된 model에 임의의 input을 넣어 output이 잘 나오는지 test\n","import segmentation_models_pytorch as smp\n","\n","model = smp.PAN(encoder_name='timm-efficientnet-b3', encoder_weights='noisy-student', classes=12)\n","x = torch.randn([2, 3, 512, 512])\n","print(\"input shape : \", x.shape)\n","out = model(x).to(device)\n","print(\"output shape : \", out.size())\n","\n","model = model.to(device)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b3_ns-9d44bf68.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b3_ns-9d44bf68.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4402a1e740bd4888b86cc4556b27c378","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=49385734.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","input shape :  torch.Size([2, 3, 512, 512])\n","output shape :  torch.Size([2, 12, 512, 512])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zvDnI7_T-NwN"},"source":["## train, validation, test 함수 정의"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-18T16:16:18.104200Z","start_time":"2021-04-18T16:16:18.093174Z"},"id":"RA3oAapJ-NwN","executionInfo":{"status":"ok","timestamp":1620204832246,"user_tz":-540,"elapsed":2024,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}}},"source":["def train(num_epochs, model, data_loader, val_loader, criterion, optimizer, saved_dir, val_every, device, lr_scheduler):\n","    print('Start training..')\n","    best_loss = 9999999\n","    best_miou = 0\n","    for epoch in range(num_epochs):\n","        model.train()\n","        for step, (images, masks, _) in enumerate(data_loader):\n","            images = torch.stack(images)       # (batch, channel, height, width)\n","            masks = torch.stack(masks).long()  # (batch, channel, height, width)\n","            \n","            # gpu 연산을 위해 device 할당\n","            images, masks = images.to(device), masks.to(device)\n","                  \n","            # inference\n","            outputs = model(images)\n","            \n","            # loss 계산 (cross entropy loss)\n","            loss = criterion(outputs, masks)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            lr_scheduler.step()\n","            \n","            # step 주기에 따른 loss 출력\n","            if (step + 1) % 25 == 0:\n","                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n","                    epoch+1, num_epochs, step+1, len(train_loader), loss.item()))\n","        \n","        # validation 주기에 따른 loss 출력 및 best model 저장\n","        if (epoch + 1) % val_every == 0:\n","#             avrg_loss = validation(epoch + 1, model, val_loader, criterion, device)\n","#             if avrg_loss < best_loss:\n","#                 print('Best performance at epoch: {}'.format(epoch + 1))\n","#                 print('Save model in', saved_dir)\n","#                 best_loss = avrg_loss\n","#                 wandb.log({'best_loss': best_loss})\n","#                 save_model(model, saved_dir)\n","            avrg_miou = validation(epoch + 1, model, val_loader, criterion, device)\n","            if avrg_miou > best_miou:\n","                print('Best performance at epoch: {}'.format(epoch + 1))\n","                print('Save model in', saved_dir)\n","                best_miou = avrg_miou\n","                wandb.log({'best_miou': best_miou})\n","                save_model(model, saved_dir)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-18T16:16:18.285795Z","start_time":"2021-04-18T16:16:18.267686Z"},"id":"EulIikmq-NwO","executionInfo":{"status":"ok","timestamp":1620204833346,"user_tz":-540,"elapsed":3102,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}}},"source":["def validation(epoch, model, data_loader, criterion, device):\n","    print('Start validation #{}'.format(epoch))\n","    model.eval()\n","    with torch.no_grad():\n","        total_loss = 0\n","        cnt = 0\n","        mIoU_list = []\n","        for step, (images, masks, _) in enumerate(data_loader):\n","            \n","            images = torch.stack(images)       # (batch, channel, height, width)\n","            masks = torch.stack(masks).long()  # (batch, channel, height, width)\n","\n","            images, masks = images.to(device), masks.to(device)            \n","\n","            outputs = model(images)\n","            loss = criterion(outputs, masks)\n","            total_loss += loss\n","            cnt += 1\n","            \n","#             print(outputs.shape)\n","#             print(masks.shape)\n","#             wandb.log(wandb.Image(images, masks={\n","#               \"predictions\" : {\n","#                 \"mask_data\" : torch.squeeze(torch.squeeze(outputs, 0),1),\n","#                 \"class_labels\" : classes_dict\n","#               },\n","#               \"ground_truth\" : {\n","#                 \"mask_data\" : torch.squeeze(masks, 0),\n","#                 \"class_labels\" : classes_dict\n","#               }\n","#             }))\n","            \n","            outputs = torch.argmax(outputs.squeeze(), dim=1).detach().cpu().numpy()\n","\n","            mIoU = label_accuracy_score(masks.detach().cpu().numpy(), outputs, n_class=12)[2]\n","            mIoU_list.append(mIoU)\n","            \n","        avrg_loss = total_loss / cnt\n","        avrg_mIoU = np.mean(mIoU_list)\n","        print('Validation #{}  Average Loss: {:.4f}, mIoU: {:.4f}'.format(epoch, avrg_loss, np.mean(mIoU_list)))\n","        wandb.log({'Train Loss':loss.item(), 'Val Loss':avrg_loss , 'Val mIoU':np.mean(mIoU_list)})\n","#     return avrg_loss\n","    return avrg_mIoU"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C_7CtFfH-NwO"},"source":["## 모델 저장 함수 정의"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-18T16:16:18.909918Z","start_time":"2021-04-18T16:16:18.898918Z"},"id":"gpCM5BFO-NwO"},"source":["# 모델 저장 함수 정의\n","val_every = 1 \n","\n","saved_dir = './saved'\n","if not os.path.isdir(saved_dir):                                                           \n","    os.mkdir(saved_dir)\n","    \n","def save_model(model, saved_dir, file_name='re_pan_effb3_noisy_focal_madgrad_cosLR.pt'):\n","    check_point = {'net': model.state_dict()}\n","    output_path = os.path.join(saved_dir, file_name)\n","    torch.save(model.state_dict(), output_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FyKGeg8T-NwP"},"source":["## 모델 생성 및 Loss function, Optimizer 정의"]},{"cell_type":"code","metadata":{"id":"ORugl8s1-NwP"},"source":["from torch.autograd import Variable\n","import torch.nn.functional as F\n","# ref : https://github.com/clcarwin/focal_loss_pytorch\n","class FocalLoss(nn.Module):\n","    def __init__(self, gamma=0, alpha=None, size_average=True):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.alpha = alpha\n","        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n","        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n","        self.size_average = size_average\n","\n","    def forward(self, input, target):\n","        if input.dim()>2:\n","            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n","            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n","            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n","        target = target.view(-1,1)\n","\n","        logpt = F.log_softmax(input)\n","        logpt = logpt.gather(1,target)\n","        logpt = logpt.view(-1)\n","        pt = Variable(logpt.data.exp())\n","\n","        if self.alpha is not None:\n","            if self.alpha.type()!=input.data.type():\n","                self.alpha = self.alpha.type_as(input.data)\n","            at = self.alpha.gather(0,target.data.view(-1))\n","            logpt = logpt * Variable(at)\n","\n","        loss = -1 * (1-pt)**self.gamma * logpt\n","        if self.size_average: return loss.mean()\n","        else: return loss.sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yfeFQknz-NwP"},"source":["import torch.optim.lr_scheduler as lr_scheduler\n","import math\n","class CosineAnnealingWarmUpRestart(lr_scheduler._LRScheduler):\n","    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n","        if T_0 <= 0 or not isinstance(T_0, int):\n","            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n","        if T_mult < 1 or not isinstance(T_mult, int):\n","            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n","        if T_up < 0 or not isinstance(T_up, int):\n","            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n","        self.T_0 = T_0\n","        self.T_mult = T_mult\n","        self.base_eta_max = eta_max\n","        self.eta_max = eta_max\n","        self.T_up = T_up\n","        self.T_i = T_0\n","        self.gamma = gamma\n","        self.cycle = 0\n","        self.T_cur = last_epoch\n","        super(CosineAnnealingWarmUpRestart, self).__init__(optimizer, last_epoch)\n","        # self.T_cur = last_epoch\n","    \n","    def get_lr(self):\n","        if self.T_cur == -1:\n","            return self.base_lrs\n","        elif self.T_cur < self.T_up:\n","            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n","        else:\n","            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n","                    for base_lr in self.base_lrs]\n","\n","    def step(self, epoch=None):\n","        if epoch is None:\n","            epoch = self.last_epoch + 1\n","            self.T_cur = self.T_cur + 1\n","            if self.T_cur >= self.T_i:\n","                self.cycle += 1\n","                self.T_cur = self.T_cur - self.T_i\n","                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n","        else:\n","            if epoch >= self.T_0:\n","                if self.T_mult == 1:\n","                    self.T_cur = epoch % self.T_0\n","                    self.cycle = epoch // self.T_0\n","                else:\n","                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n","                    self.cycle = n\n","                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n","                    self.T_i = self.T_0 * self.T_mult ** (n)\n","            else:\n","                self.T_i = self.T_0\n","                self.T_cur = epoch\n","                \n","        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n","        self.last_epoch = math.floor(epoch)\n","        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n","            param_group['lr'] = lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AG1oQeu7BX1M","executionInfo":{"status":"ok","timestamp":1620060019354,"user_tz":-540,"elapsed":3477,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"98eae7c4-b66e-409d-9725-0c684d747f2a"},"source":["# !pip install adamp"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: adamp in /usr/local/lib/python3.7/dist-packages (0.3.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eH2PpwF9a-Os","executionInfo":{"status":"ok","timestamp":1620085557624,"user_tz":-540,"elapsed":3897,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"a78e14f8-d5e3-419d-a790-dda6f857e227"},"source":["!pip install madgrad"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting madgrad\n","  Downloading https://files.pythonhosted.org/packages/65/f0/4584f18202a2fb8903d456bf907b80e7cb54ad8fcba68604084ff41b7cf8/madgrad-1.1-py3-none-any.whl\n","Installing collected packages: madgrad\n","Successfully installed madgrad-1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-18T16:16:19.698902Z","start_time":"2021-04-18T16:16:19.694902Z"},"id":"9Dly8KZj-NwQ"},"source":["# from adamp import AdamP\n","from madgrad import MADGRAD\n","# Loss function 정의\n","# criterion = nn.CrossEntropyLoss()\n","criterion = FocalLoss()\n","\n","# Optimizer 정의\n","# optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate, weight_decay=1e-6)\n","# optimizer = AdamP(params = model.parameters())\n","optimizer = MADGRAD(params = model.parameters(), lr = learning_rate, momentum = 0.9, weight_decay = 0, eps = 1e-06)\n","\n","# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 237, gamma = 0.65)\n","lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0)\n","# lr_scheduler = CosineAnnealingWarmUpRestart(optimizer, T_0=150, T_mult=1, eta_max=0.1,  T_up=10, gamma=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"start_time":"2021-04-18T16:16:20.331Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"cMSiFA-3-NwR","executionInfo":{"status":"ok","timestamp":1620102365361,"user_tz":-540,"elapsed":16802515,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"4a8d5ffa-5ba1-47b5-f7c3-2c6bcfa02fb6"},"source":["train(num_epochs, model, train_loader, val_loader, criterion, optimizer, saved_dir, val_every, device, lr_scheduler)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Start training..\n","Epoch [1/20], Step [25/327], Loss: 0.8220\n","Epoch [1/20], Step [50/327], Loss: 0.9693\n","Epoch [1/20], Step [75/327], Loss: 0.5957\n","Epoch [1/20], Step [100/327], Loss: 0.5607\n","Epoch [1/20], Step [125/327], Loss: 0.6950\n","Epoch [1/20], Step [150/327], Loss: 0.3106\n","Epoch [1/20], Step [175/327], Loss: 0.4186\n","Epoch [1/20], Step [200/327], Loss: 0.4975\n","Epoch [1/20], Step [225/327], Loss: 0.4637\n","Epoch [1/20], Step [250/327], Loss: 0.3797\n","Epoch [1/20], Step [275/327], Loss: 0.2911\n","Epoch [1/20], Step [300/327], Loss: 0.3394\n","Epoch [1/20], Step [325/327], Loss: 0.9269\n","Start validation #1\n","Validation #1  Average Loss: 0.4036, mIoU: 0.3302\n","Best performance at epoch: 1\n","Save model in ./saved\n","Epoch [2/20], Step [25/327], Loss: 0.4637\n","Epoch [2/20], Step [50/327], Loss: 0.3740\n","Epoch [2/20], Step [75/327], Loss: 0.2870\n","Epoch [2/20], Step [100/327], Loss: 0.4495\n","Epoch [2/20], Step [125/327], Loss: 0.2755\n","Epoch [2/20], Step [150/327], Loss: 0.3229\n","Epoch [2/20], Step [175/327], Loss: 0.4972\n","Epoch [2/20], Step [200/327], Loss: 0.4102\n","Epoch [2/20], Step [225/327], Loss: 0.5059\n","Epoch [2/20], Step [250/327], Loss: 0.3355\n","Epoch [2/20], Step [275/327], Loss: 0.2518\n","Epoch [2/20], Step [300/327], Loss: 0.3774\n","Epoch [2/20], Step [325/327], Loss: 0.3262\n","Start validation #2\n","Validation #2  Average Loss: 0.3380, mIoU: 0.3628\n","Best performance at epoch: 2\n","Save model in ./saved\n","Epoch [3/20], Step [25/327], Loss: 0.2823\n","Epoch [3/20], Step [50/327], Loss: 0.3700\n","Epoch [3/20], Step [75/327], Loss: 0.2374\n","Epoch [3/20], Step [100/327], Loss: 0.2222\n","Epoch [3/20], Step [125/327], Loss: 0.3173\n","Epoch [3/20], Step [150/327], Loss: 0.1524\n","Epoch [3/20], Step [175/327], Loss: 0.2998\n","Epoch [3/20], Step [200/327], Loss: 0.4724\n","Epoch [3/20], Step [225/327], Loss: 0.5351\n","Epoch [3/20], Step [250/327], Loss: 0.2975\n","Epoch [3/20], Step [275/327], Loss: 0.1980\n","Epoch [3/20], Step [300/327], Loss: 0.2431\n","Epoch [3/20], Step [325/327], Loss: 0.1727\n","Start validation #3\n","Validation #3  Average Loss: 0.3223, mIoU: 0.3757\n","Best performance at epoch: 3\n","Save model in ./saved\n","Epoch [4/20], Step [25/327], Loss: 0.2651\n","Epoch [4/20], Step [50/327], Loss: 0.1643\n","Epoch [4/20], Step [75/327], Loss: 0.5499\n","Epoch [4/20], Step [100/327], Loss: 0.5083\n","Epoch [4/20], Step [125/327], Loss: 0.1990\n","Epoch [4/20], Step [150/327], Loss: 0.1870\n","Epoch [4/20], Step [175/327], Loss: 0.2616\n","Epoch [4/20], Step [200/327], Loss: 0.3783\n","Epoch [4/20], Step [225/327], Loss: 0.2177\n","Epoch [4/20], Step [250/327], Loss: 0.2972\n","Epoch [4/20], Step [275/327], Loss: 0.3182\n","Epoch [4/20], Step [300/327], Loss: 0.2135\n","Epoch [4/20], Step [325/327], Loss: 0.2213\n","Start validation #4\n","Validation #4  Average Loss: 0.3261, mIoU: 0.3845\n","Best performance at epoch: 4\n","Save model in ./saved\n","Epoch [5/20], Step [25/327], Loss: 0.2593\n","Epoch [5/20], Step [50/327], Loss: 0.1275\n","Epoch [5/20], Step [75/327], Loss: 0.1957\n","Epoch [5/20], Step [100/327], Loss: 0.1422\n","Epoch [5/20], Step [125/327], Loss: 0.3824\n","Epoch [5/20], Step [150/327], Loss: 0.1738\n","Epoch [5/20], Step [175/327], Loss: 0.2868\n","Epoch [5/20], Step [200/327], Loss: 0.1969\n","Epoch [5/20], Step [225/327], Loss: 0.3230\n","Epoch [5/20], Step [250/327], Loss: 0.3353\n","Epoch [5/20], Step [275/327], Loss: 0.2106\n","Epoch [5/20], Step [300/327], Loss: 0.2099\n","Epoch [5/20], Step [325/327], Loss: 0.1516\n","Start validation #5\n","Validation #5  Average Loss: 0.3211, mIoU: 0.3903\n","Best performance at epoch: 5\n","Save model in ./saved\n","Epoch [6/20], Step [25/327], Loss: 0.2465\n","Epoch [6/20], Step [50/327], Loss: 0.5391\n","Epoch [6/20], Step [75/327], Loss: 0.2195\n","Epoch [6/20], Step [100/327], Loss: 0.2353\n","Epoch [6/20], Step [125/327], Loss: 0.1401\n","Epoch [6/20], Step [150/327], Loss: 0.3294\n","Epoch [6/20], Step [175/327], Loss: 0.2092\n","Epoch [6/20], Step [200/327], Loss: 0.1416\n","Epoch [6/20], Step [225/327], Loss: 0.2856\n","Epoch [6/20], Step [250/327], Loss: 0.1882\n","Epoch [6/20], Step [275/327], Loss: 0.2622\n","Epoch [6/20], Step [300/327], Loss: 0.2210\n","Epoch [6/20], Step [325/327], Loss: 0.4069\n","Start validation #6\n","Validation #6  Average Loss: 0.3064, mIoU: 0.4024\n","Best performance at epoch: 6\n","Save model in ./saved\n","Epoch [7/20], Step [25/327], Loss: 0.1971\n","Epoch [7/20], Step [50/327], Loss: 0.3775\n","Epoch [7/20], Step [75/327], Loss: 0.2329\n","Epoch [7/20], Step [100/327], Loss: 0.1812\n","Epoch [7/20], Step [125/327], Loss: 0.2603\n","Epoch [7/20], Step [150/327], Loss: 0.2951\n","Epoch [7/20], Step [175/327], Loss: 0.2191\n","Epoch [7/20], Step [200/327], Loss: 0.2100\n","Epoch [7/20], Step [225/327], Loss: 0.2288\n","Epoch [7/20], Step [250/327], Loss: 0.1154\n","Epoch [7/20], Step [275/327], Loss: 0.2520\n","Epoch [7/20], Step [300/327], Loss: 0.1991\n","Epoch [7/20], Step [325/327], Loss: 0.2768\n","Start validation #7\n","Validation #7  Average Loss: 0.3020, mIoU: 0.4029\n","Best performance at epoch: 7\n","Save model in ./saved\n","Epoch [8/20], Step [25/327], Loss: 0.1435\n","Epoch [8/20], Step [50/327], Loss: 0.2481\n","Epoch [8/20], Step [75/327], Loss: 0.2333\n","Epoch [8/20], Step [100/327], Loss: 0.5998\n","Epoch [8/20], Step [125/327], Loss: 0.1876\n","Epoch [8/20], Step [150/327], Loss: 0.1315\n","Epoch [8/20], Step [175/327], Loss: 0.2060\n","Epoch [8/20], Step [200/327], Loss: 0.3043\n","Epoch [8/20], Step [225/327], Loss: 0.3325\n","Epoch [8/20], Step [250/327], Loss: 0.1677\n","Epoch [8/20], Step [275/327], Loss: 0.2762\n","Epoch [8/20], Step [300/327], Loss: 0.2651\n","Epoch [8/20], Step [325/327], Loss: 0.1829\n","Start validation #8\n","Validation #8  Average Loss: 0.3218, mIoU: 0.3910\n","Epoch [9/20], Step [25/327], Loss: 0.2955\n","Epoch [9/20], Step [50/327], Loss: 0.1504\n","Epoch [9/20], Step [75/327], Loss: 0.2052\n","Epoch [9/20], Step [100/327], Loss: 0.1681\n","Epoch [9/20], Step [125/327], Loss: 0.2105\n","Epoch [9/20], Step [150/327], Loss: 0.3958\n","Epoch [9/20], Step [175/327], Loss: 0.2038\n","Epoch [9/20], Step [200/327], Loss: 0.1581\n","Epoch [9/20], Step [225/327], Loss: 0.2321\n","Epoch [9/20], Step [250/327], Loss: 0.5859\n","Epoch [9/20], Step [275/327], Loss: 0.1786\n","Epoch [9/20], Step [300/327], Loss: 0.2025\n","Epoch [9/20], Step [325/327], Loss: 0.2564\n","Start validation #9\n","Validation #9  Average Loss: 0.3119, mIoU: 0.3999\n","Epoch [10/20], Step [25/327], Loss: 0.2226\n","Epoch [10/20], Step [50/327], Loss: 0.2789\n","Epoch [10/20], Step [75/327], Loss: 0.2737\n","Epoch [10/20], Step [100/327], Loss: 0.1672\n","Epoch [10/20], Step [125/327], Loss: 0.2229\n","Epoch [10/20], Step [150/327], Loss: 0.1895\n","Epoch [10/20], Step [175/327], Loss: 0.2673\n","Epoch [10/20], Step [200/327], Loss: 0.1930\n","Epoch [10/20], Step [225/327], Loss: 0.2665\n","Epoch [10/20], Step [250/327], Loss: 0.2793\n","Epoch [10/20], Step [275/327], Loss: 0.1416\n","Epoch [10/20], Step [300/327], Loss: 0.1874\n","Epoch [10/20], Step [325/327], Loss: 0.2545\n","Start validation #10\n","Validation #10  Average Loss: 0.3110, mIoU: 0.4005\n","Epoch [11/20], Step [25/327], Loss: 0.1683\n","Epoch [11/20], Step [50/327], Loss: 0.1382\n","Epoch [11/20], Step [75/327], Loss: 0.2597\n","Epoch [11/20], Step [100/327], Loss: 0.1811\n","Epoch [11/20], Step [125/327], Loss: 0.1636\n","Epoch [11/20], Step [150/327], Loss: 0.2341\n","Epoch [11/20], Step [175/327], Loss: 0.1371\n","Epoch [11/20], Step [200/327], Loss: 0.1651\n","Epoch [11/20], Step [225/327], Loss: 0.1613\n","Epoch [11/20], Step [250/327], Loss: 0.2747\n","Epoch [11/20], Step [275/327], Loss: 0.2168\n","Epoch [11/20], Step [300/327], Loss: 0.1324\n","Epoch [11/20], Step [325/327], Loss: 0.1794\n","Start validation #11\n","Validation #11  Average Loss: 0.3163, mIoU: 0.3971\n","Epoch [12/20], Step [25/327], Loss: 0.2183\n","Epoch [12/20], Step [50/327], Loss: 0.2838\n","Epoch [12/20], Step [75/327], Loss: 0.1586\n","Epoch [12/20], Step [100/327], Loss: 0.1709\n","Epoch [12/20], Step [125/327], Loss: 0.1035\n","Epoch [12/20], Step [150/327], Loss: 0.2441\n","Epoch [12/20], Step [175/327], Loss: 0.1597\n","Epoch [12/20], Step [200/327], Loss: 0.2000\n","Epoch [12/20], Step [225/327], Loss: 0.1169\n","Epoch [12/20], Step [250/327], Loss: 0.2083\n","Epoch [12/20], Step [275/327], Loss: 0.1702\n","Epoch [12/20], Step [300/327], Loss: 0.2536\n","Epoch [12/20], Step [325/327], Loss: 0.2076\n","Start validation #12\n","Validation #12  Average Loss: 0.3084, mIoU: 0.3996\n","Epoch [13/20], Step [25/327], Loss: 0.1396\n","Epoch [13/20], Step [50/327], Loss: 0.2793\n","Epoch [13/20], Step [75/327], Loss: 0.2214\n","Epoch [13/20], Step [100/327], Loss: 0.1829\n","Epoch [13/20], Step [125/327], Loss: 0.1186\n","Epoch [13/20], Step [150/327], Loss: 0.2502\n","Epoch [13/20], Step [175/327], Loss: 0.1820\n","Epoch [13/20], Step [200/327], Loss: 0.2334\n","Epoch [13/20], Step [225/327], Loss: 0.2726\n","Epoch [13/20], Step [250/327], Loss: 0.2181\n","Epoch [13/20], Step [275/327], Loss: 0.2053\n","Epoch [13/20], Step [300/327], Loss: 0.1475\n","Epoch [13/20], Step [325/327], Loss: 0.2240\n","Start validation #13\n","Validation #13  Average Loss: 0.3037, mIoU: 0.4046\n","Best performance at epoch: 13\n","Save model in ./saved\n","Epoch [14/20], Step [25/327], Loss: 0.1344\n","Epoch [14/20], Step [50/327], Loss: 0.1763\n","Epoch [14/20], Step [75/327], Loss: 0.2505\n","Epoch [14/20], Step [100/327], Loss: 0.2819\n","Epoch [14/20], Step [125/327], Loss: 0.1049\n","Epoch [14/20], Step [150/327], Loss: 0.1711\n","Epoch [14/20], Step [175/327], Loss: 0.1770\n","Epoch [14/20], Step [200/327], Loss: 0.2304\n","Epoch [14/20], Step [225/327], Loss: 0.2550\n","Epoch [14/20], Step [250/327], Loss: 0.1755\n","Epoch [14/20], Step [275/327], Loss: 0.1470\n","Epoch [14/20], Step [300/327], Loss: 0.1680\n","Epoch [14/20], Step [325/327], Loss: 0.1469\n","Start validation #14\n","Validation #14  Average Loss: 0.3078, mIoU: 0.4008\n","Epoch [15/20], Step [25/327], Loss: 0.2224\n","Epoch [15/20], Step [50/327], Loss: 0.1466\n","Epoch [15/20], Step [75/327], Loss: 0.2352\n","Epoch [15/20], Step [100/327], Loss: 0.1803\n","Epoch [15/20], Step [125/327], Loss: 0.3149\n","Epoch [15/20], Step [150/327], Loss: 0.2038\n","Epoch [15/20], Step [175/327], Loss: 0.3633\n","Epoch [15/20], Step [200/327], Loss: 0.3436\n","Epoch [15/20], Step [225/327], Loss: 0.3966\n","Epoch [15/20], Step [250/327], Loss: 0.1886\n","Epoch [15/20], Step [275/327], Loss: 0.2162\n","Epoch [15/20], Step [300/327], Loss: 0.2388\n","Epoch [15/20], Step [325/327], Loss: 0.2111\n","Start validation #15\n","Validation #15  Average Loss: 0.3039, mIoU: 0.4039\n","Epoch [16/20], Step [25/327], Loss: 0.2404\n","Epoch [16/20], Step [50/327], Loss: 0.1919\n","Epoch [16/20], Step [75/327], Loss: 0.1601\n","Epoch [16/20], Step [100/327], Loss: 0.1066\n","Epoch [16/20], Step [125/327], Loss: 0.2508\n","Epoch [16/20], Step [150/327], Loss: 0.3109\n","Epoch [16/20], Step [175/327], Loss: 0.1376\n","Epoch [16/20], Step [200/327], Loss: 0.3027\n","Epoch [16/20], Step [225/327], Loss: 0.2755\n","Epoch [16/20], Step [250/327], Loss: 0.1969\n","Epoch [16/20], Step [275/327], Loss: 0.1959\n","Epoch [16/20], Step [300/327], Loss: 0.2527\n","Epoch [16/20], Step [325/327], Loss: 0.1785\n","Start validation #16\n","Validation #16  Average Loss: 0.3170, mIoU: 0.3962\n","Epoch [17/20], Step [25/327], Loss: 0.2603\n","Epoch [17/20], Step [50/327], Loss: 0.1757\n","Epoch [17/20], Step [75/327], Loss: 0.1134\n","Epoch [17/20], Step [100/327], Loss: 0.2251\n","Epoch [17/20], Step [125/327], Loss: 0.1246\n","Epoch [17/20], Step [150/327], Loss: 0.1843\n","Epoch [17/20], Step [175/327], Loss: 0.1178\n","Epoch [17/20], Step [200/327], Loss: 0.1842\n","Epoch [17/20], Step [225/327], Loss: 0.1353\n","Epoch [17/20], Step [250/327], Loss: 0.3383\n","Epoch [17/20], Step [275/327], Loss: 0.1871\n","Epoch [17/20], Step [300/327], Loss: 0.3401\n","Epoch [17/20], Step [325/327], Loss: 0.2371\n","Start validation #17\n","Validation #17  Average Loss: 0.3028, mIoU: 0.4015\n","Epoch [18/20], Step [25/327], Loss: 0.1990\n","Epoch [18/20], Step [50/327], Loss: 0.1347\n","Epoch [18/20], Step [75/327], Loss: 0.2431\n","Epoch [18/20], Step [100/327], Loss: 0.1710\n","Epoch [18/20], Step [125/327], Loss: 0.1884\n","Epoch [18/20], Step [150/327], Loss: 0.2045\n","Epoch [18/20], Step [175/327], Loss: 0.1383\n","Epoch [18/20], Step [200/327], Loss: 0.2550\n","Epoch [18/20], Step [225/327], Loss: 0.1336\n","Epoch [18/20], Step [250/327], Loss: 0.1860\n","Epoch [18/20], Step [275/327], Loss: 0.3575\n","Epoch [18/20], Step [300/327], Loss: 0.1588\n","Epoch [18/20], Step [325/327], Loss: 0.0986\n","Start validation #18\n","Validation #18  Average Loss: 0.3105, mIoU: 0.3947\n","Epoch [19/20], Step [25/327], Loss: 0.1259\n","Epoch [19/20], Step [50/327], Loss: 0.1682\n","Epoch [19/20], Step [75/327], Loss: 0.2996\n","Epoch [19/20], Step [100/327], Loss: 0.1441\n","Epoch [19/20], Step [125/327], Loss: 0.5350\n","Epoch [19/20], Step [150/327], Loss: 0.2107\n","Epoch [19/20], Step [175/327], Loss: 0.1675\n","Epoch [19/20], Step [200/327], Loss: 0.1417\n","Epoch [19/20], Step [225/327], Loss: 0.2037\n","Epoch [19/20], Step [250/327], Loss: 0.1059\n","Epoch [19/20], Step [275/327], Loss: 0.0922\n","Epoch [19/20], Step [300/327], Loss: 0.2640\n","Epoch [19/20], Step [325/327], Loss: 0.2383\n","Start validation #19\n","Validation #19  Average Loss: 0.3082, mIoU: 0.4029\n","Epoch [20/20], Step [25/327], Loss: 0.5513\n","Epoch [20/20], Step [50/327], Loss: 0.1728\n","Epoch [20/20], Step [75/327], Loss: 0.2459\n","Epoch [20/20], Step [100/327], Loss: 0.3029\n","Epoch [20/20], Step [125/327], Loss: 0.2330\n","Epoch [20/20], Step [150/327], Loss: 0.1795\n","Epoch [20/20], Step [175/327], Loss: 0.1673\n","Epoch [20/20], Step [200/327], Loss: 0.2743\n","Epoch [20/20], Step [225/327], Loss: 0.2923\n","Epoch [20/20], Step [250/327], Loss: 0.2168\n","Epoch [20/20], Step [275/327], Loss: 0.1909\n","Epoch [20/20], Step [300/327], Loss: 0.1407\n","Epoch [20/20], Step [325/327], Loss: 0.2757\n","Start validation #20\n","Validation #20  Average Loss: 0.3049, mIoU: 0.4011\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C6ClcO0J-NwR"},"source":["## 저장된 model 불러오기 (학습된 이후) "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-16T19:44:21.050200Z","start_time":"2021-04-16T19:44:20.802200Z"},"scrolled":true,"id":"KQPtUDzd-NwR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620205133254,"user_tz":-540,"elapsed":3334,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"77835d9f-aeaa-45d4-e1b7-58cb87a720a0"},"source":["# best model 저장된 경로\n","model_path = './saved/re_pan_aug2_re_pan_effb3_noisy_focal_madgrad_cosLReffb7_noisy_focal_madgrad_cosLR.pt'\n","\n","# best model 불러오기\n","checkpoint = torch.load(model_path, map_location=device)\n","model.load_state_dict(checkpoint)\n","\n","# 추론을 실행하기 전에는 반드시 설정 (batch normalization, dropout 를 평가 모드로 설정)\n","# model.eval()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-16T19:44:24.939227Z","start_time":"2021-04-16T19:44:24.518228Z"},"id":"0LQqrDAp-NwR","colab":{"base_uri":"https://localhost:8080/","height":409},"executionInfo":{"status":"error","timestamp":1620205140385,"user_tz":-540,"elapsed":3173,"user":{"displayName":"신찬엽","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjIFu8yE_RMQcdyWMMm8-WUcSPg1PVDbrOp0NO6Yg=s64","userId":"00918694046621707424"}},"outputId":"ac51f4c0-fd51-4e94-d4e6-73180806d6fc"},"source":["# 첫번째 batch의 추론 결과 확인\n","for imgs, image_infos in test_loader:\n","    image_infos = image_infos\n","    temp_images = imgs\n","    \n","    model.eval()\n","    # inference\n","    outs = model(torch.stack(temp_images).to(device))\n","    oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n","    \n","    break\n","\n","i = 1\n","fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\n","\n","print('Shape of Original Image :', list(temp_images[i].shape))\n","print('Shape of Predicted : ', list(oms[i].shape))\n","print('Unique values, category of transformed mask : \\n', [{int(i),category_names[int(i)]} for i in list(np.unique(oms[i]))])\n","\n","# Original image\n","ax1.imshow(temp_images[i].permute([1,2,0]))\n","ax1.grid(False)\n","ax1.set_title(\"Original image : {}\".format(image_infos[i]['file_name']), fontsize = 15)\n","\n","# Predicted\n","ax2.imshow(oms[i])\n","ax2.grid(False)\n","ax2.set_title(\"Predicted : {}\".format(image_infos[i]['file_name']), fontsize = 15)\n","\n","plt.show()"],"execution_count":23,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-6f5319a1a524>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0moms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/segmentation_models_pytorch/base/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m\"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/segmentation_models_pytorch/encoders/timm_efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 80.00 MiB (GPU 0; 15.90 GiB total capacity; 14.86 GiB already allocated; 81.75 MiB free; 14.94 GiB reserved in total by PyTorch)"]}]},{"cell_type":"markdown","metadata":{"id":"evYjR2F3-NwS"},"source":["## submission을 위한 test 함수 정의"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-16T19:44:27.469285Z","start_time":"2021-04-16T19:44:27.456021Z"},"id":"nhMLnV5d-NwS"},"source":["def test(model, data_loader, device):\n","    size = 256\n","    transform = A.Compose([A.Resize(256, 256)])\n","    print('Start prediction.')\n","    model.eval()\n","    \n","    file_name_list = []\n","    preds_array = np.empty((0, size*size), dtype=np.long)\n","    \n","    with torch.no_grad():\n","        for step, (imgs, image_infos) in enumerate(test_loader):\n","\n","            # inference (512 x 512)\n","            outs = model(torch.stack(imgs).to(device))\n","            oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n","            \n","            # resize (256 x 256)\n","            temp_mask = []\n","            for img, mask in zip(np.stack(imgs), oms):\n","                transformed = transform(image=img, mask=mask)\n","                mask = transformed['mask']\n","                temp_mask.append(mask)\n","\n","            oms = np.array(temp_mask)\n","            \n","            oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n","            preds_array = np.vstack((preds_array, oms))\n","            \n","            file_name_list.append([i['file_name'] for i in image_infos])\n","    print(\"End prediction.\")\n","    file_names = [y for x in file_name_list for y in x]\n","    \n","    return file_names, preds_array"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r1YKHBf4-NwT"},"source":["## submission.csv 생성"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-16T19:45:42.235310Z","start_time":"2021-04-16T19:44:30.499016Z"},"scrolled":true,"id":"Bz79_g8K-NwT"},"source":["# sample_submisson.csv 열기\n","submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n","\n","# test set에 대한 prediction\n","file_names, preds = test(model, test_loader, device) # 여가\n","\n","# PredictionString 대입\n","for file_name, string in zip(file_names, preds):\n","    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n","                                   ignore_index=True)\n","\n","# submission.csv로 저장\n","submission.to_csv(\"./submission/pan_effb3_noisy_focal_adamp_cosLR.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zgl7Ye7F-NwT"},"source":["## 제출까지\n","\n"]},{"cell_type":"code","metadata":{"id":"022E8AC7-NwT"},"source":["import json\n","import requests\n","import os\n","from urllib.parse import urlparse, parse_qsl, urlencode, urlunparse\n","\n","def submit(user_key='', file_path = '', desc=\"\"):\n","    if not user_key:\n","        raise Exception(\"No UserKey\" )\n","    url = urlparse('http://ec2-13-124-161-225.ap-northeast-2.compute.amazonaws.com:8000/api/v1/competition/28/presigned_url/?description=&hyperparameters={%22training%22:{},%22inference%22:{}}')\n","    qs = dict(parse_qsl(url.query))\n","    qs['description'] = desc\n","    parts = url._replace(query=urlencode(qs))\n","    url = urlunparse(parts)\n","\n","    print(url)\n","    headers = {\n","        'Authorization': user_key\n","    }\n","    res = requests.get(url, headers=headers)\n","    print(res.text)\n","    data = json.loads(res.text)\n","    \n","    submit_url = data['url']\n","    body = {\n","        'key':'app/Competitions/000028/Users/{}/Submissions/{}/output.csv'.format(str(data['submission']['user']).zfill(8),str(data['submission']['local_id']).zfill(4)),\n","        'x-amz-algorithm':data['fields']['x-amz-algorithm'],\n","        'x-amz-credential':data['fields']['x-amz-credential'],\n","        'x-amz-date':data['fields']['x-amz-date'],\n","        'policy':data['fields']['policy'],\n","        'x-amz-signature':data['fields']['x-amz-signature']\n","    }\n","    requests.post(url=submit_url, data=body, files={'file': open(file_path, 'rb')})\n","\n","\n","####################################################################################\n","test_dir = \"/opt/ml/code/submission\"  # 수정 필요 : output 파일 폴더 \n","desc = 'pan_effb3_noisy_focal_adamp_cosLR'  # 수정 필요 : 파일에 대한 설명\n","output_file = \"pan_effb3_noisy_focal_adamp_cosLR.csv\" #수정 필요  : output 파일 \n","user_key = \"Bearer 7bb5f96452751a238ffaf91a93c4242bf9b72abe\"        # 수정 필요 : Authorization \n","\n","\n","submit(user_key, os.path.join(test_dir, output_file),desc)"],"execution_count":null,"outputs":[]}]}